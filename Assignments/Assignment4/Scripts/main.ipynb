{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d6a9b3f",
   "metadata": {},
   "source": [
    "Assignment 4\n",
    "\n",
    "Code\n",
    "1. Admin stuff: Loading all libraries and data\n",
    "2. data preprocessing\n",
    "3. Kaplan-Meier Analysis\n",
    "4. Cox Proportional Hazards Regression\n",
    "5. Random Survival Forests (RSF)\n",
    "\n",
    "Things to improve: \n",
    "- RSF runs for a long time which makes me thing i didn't close some loop. I fixed a lot of minor errors but it's hard to know what to fix when it never stops running. \n",
    "- I didn't compare the RSF modelâ€™s concordance index (C-index) with that of Cox regression.\n",
    "- Adding training and testing split.\n",
    "- Adding better annotations.\n",
    "\n",
    "\n",
    "References (all accessed July 15-17.2025):\n",
    "\n",
    "- https://lifelines.readthedocs.io/en/latest/lifelines.statistics.html - multivariate_logrank_test\n",
    "\n",
    "- https://scikit-survival.readthedocs.io/en/stable/user_guide/random-survival-forest.html - random survival forest\n",
    "\n",
    "AI was used for a lot of troubleshooting and pointing to resources mostly for RSF. I looked at code examples online, more than I pasted as references. Some annotations. Probably help with readme but I didn't write it yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51dbba4b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "### Admin stuff ###\n",
    "import data_preprocessor as dp\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from lifelines import KaplanMeierFitter\n",
    "from lifelines.statistics import multivariate_logrank_test\n",
    "from lifelines import CoxPHFitter\n",
    "from sksurv.ensemble import RandomSurvivalForest\n",
    "from sksurv.util import Surv\n",
    "from sksurv.preprocessing import OneHotEncoder as SKSurvEncoder\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "### loading data ###\n",
    "messy_data = pd.read_excel(r'../Data/RADCURE_Clinical_v04_20241219.xlsx', na_values=['', 'NA', 'Na', 'null', \"\"])\n",
    "working_data = messy_data.copy()\n",
    "#working_data.to_csv(r\"../Data/cleaning_step0.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff240da1",
   "metadata": {},
   "source": [
    "All data exploration was done in data wrangler extension of vscode.\n",
    "\n",
    "I followed the usual data cleaning steps: dropping duplicates, removing columns and rows with 25+% missing data, dropping the rows with other missing data (\"subsite\" column had 11% of missing data. I decided to delete those too although I could have added ex \"unknown\" value instead. But at the end I still had almost 3k rows so I decided on deleting those rows)\n",
    "\n",
    "Finally I used \"Status\" column to make a binary \"Event\" column for survival. And I defined duration and event columns.\n",
    "\n",
    "Final stats: messy data = 3,346 rows x 34 columns, clean data = 2,946 rows x 24 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313a78b1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "### cleaning the data ###\n",
    "working_data = working_data.drop_duplicates()\n",
    "working_data = dp.remove_columns_missing_data(working_data)\n",
    "working_data = dp.remove_rows_missing_data(working_data)\n",
    "#working_data.to_csv(r\"../Data/cleaning_step2.csv\", index=False)\n",
    "\n",
    "# print(working_data.columns.tolist())\n",
    "columns = [\"Smoking PY\", \"Subsite\",\"T\",\"N\",\"M \",\"Stage\"]\n",
    "working_data = working_data.dropna(subset = columns)\n",
    "#working_data.to_csv(r\"../Data/cleaning_step3.csv\", index=False)\n",
    "\n",
    "# add event column\n",
    "working_data['Event'] = working_data['Status'].map({'Dead': 1, 'Alive': 0})\n",
    "working_data.to_csv(r\"../Data/clean_data.csv\", index=False)\n",
    "\n",
    "clean_data = working_data\n",
    "\n",
    "duration = \"Length FU\"\n",
    "event = \"Event\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cad3056",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "### Kaplan-Meier Analysis ###\n",
    "# 2 groups chosen: Stage and Chemo\n",
    "\n",
    "kmf = KaplanMeierFitter()\n",
    "\n",
    "## KM curves by stage\n",
    "for stage, group in clean_data.groupby(\"Stage\"):\n",
    "    kmf.fit(group[duration], event_observed = group[event], label = f\"Stage {stage}\")\n",
    "    kmf.plot_survival_function()\n",
    "\n",
    "# Plot the Kaplan-Meier curve\n",
    "kmf.plot_survival_function()\n",
    "plt.title('Kaplan-Meier Curve')\n",
    "plt.xlabel('Time (weeks)')\n",
    "plt.ylabel('Survival Probability')\n",
    "plt.show()\n",
    "\n",
    "# multivariate_logrank_test for stage comparison\n",
    "result = multivariate_logrank_test(\n",
    "    event_durations=clean_data[duration],\n",
    "    groups=clean_data[\"Stage\"],\n",
    "    event_observed=clean_data[event])\n",
    "result.print_summary()\n",
    "\n",
    "## KM curves by chemo\n",
    "for chemo, group in clean_data.groupby(\"Chemo\"):\n",
    "    kmf.fit(group[duration], event_observed = group[event], label = chemo)\n",
    "    kmf.plot_survival_function()\n",
    "\n",
    "# Plot the Kaplan-Meier curve\n",
    "kmf.plot_survival_function()\n",
    "plt.title('Kaplan-Meier Curve')\n",
    "plt.xlabel('Time (weeks)')\n",
    "plt.ylabel('Survival Probability')\n",
    "plt.show()\n",
    "\n",
    "# multivariate_logrank_test for chemo comparison. I chose to use this one for speed even though it's binary.\n",
    "result = multivariate_logrank_test(\n",
    "    event_durations=clean_data[duration],\n",
    "    groups=clean_data[\"Chemo\"],\n",
    "    event_observed=clean_data[event])\n",
    "result.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db3ba2f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "### Cox Proportional Hazards Regression ###\n",
    "\n",
    "# convert to binary and dummy\n",
    "covariates = [\"Chemo\", \"Sex\", \"Stage\"]\n",
    "cox_data = clean_data[[duration, event] + covariates].copy()\n",
    "cox_data[\"Chemo\"] = cox_data[\"Chemo\"].map({\"Yes\": 1, \"none\": 0})\n",
    "cox_data[\"Sex\"] = cox_data[\"Sex\"].map({\"Female\": 1, \"Male\": 0})\n",
    "cox_data = pd.get_dummies(cox_data, columns=[\"Stage\"], drop_first=True)\n",
    "cox_data = cox_data.drop(columns=[\"Stage_IB\", \"Stage_IIA\", \"Stage_IVC\"]) # made the plot unreadable\n",
    "\n",
    "# CPH model\n",
    "cph = CoxPHFitter()\n",
    "cph.fit(cox_data,\n",
    "        duration_col=duration, event_col=event)\n",
    "cph.print_summary()\n",
    "\n",
    "# plot \n",
    "cph.plot()\n",
    "plt.title('Cox Regression Coefficients')\n",
    "plt.show()\n",
    "\n",
    "# check assumptions\n",
    "cph.check_assumptions(cox_data, p_value_threshold=0.05, show_plots=True)\n",
    "# Stage_IVB failed the assumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0477e0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "### Random Survival Forests (RSF) ###\n",
    "\n",
    "# prep data\n",
    "rsf_data = clean_data[[duration, event] + covariates].copy()\n",
    "rsf_data[\"Chemo\"] = rsf_data[\"Chemo\"].map({\"Yes\": 1, \"none\": 0})\n",
    "rsf_data[\"Sex\"] = rsf_data[\"Sex\"].map({\"Female\": 1, \"Male\": 0})\n",
    "rsf_data = rsf_data.select_dtypes(exclude=[\"datetime64[ns]\"])\n",
    "\n",
    "data_x = rsf_data.drop(columns=[duration, event], axis=1)\n",
    "data_y = Surv.from_dataframe(event=event, time=duration, data=rsf_data)\n",
    "for col in data_x.select_dtypes(include=\"object\").columns:\n",
    "    data_x[col] = data_x[col].astype(\"category\")\n",
    "\n",
    "encoder = SKSurvEncoder()\n",
    "data_x = encoder.fit_transform(data_x)\n",
    "\n",
    "# survival model\n",
    "rsf = RandomSurvivalForest(n_estimators=100, random_state=42)\n",
    "rsf.fit(data_x, data_y)\n",
    "\n",
    "result = permutation_importance(rsf, data_x, data_y, n_repeats=15, random_state=42)\n",
    "feature_importance = pd.DataFrame(\n",
    "         {\n",
    "        k: result[k]\n",
    "        for k in (\n",
    "            \"importances_mean\",\n",
    "            \"importances_std\",\n",
    "        )\n",
    "    },\n",
    "    index=data_x.columns,\n",
    ").sort_values(by=\"importances_mean\", ascending=False)\n",
    "\n",
    "# Sort by importances_mean and plot\n",
    "feature_importance = feature_importance.sort_values(by=\"importances_mean\", ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(feature_importance.index, feature_importance['importances_mean'], xerr=feature_importance['importances_std'], align='center')\n",
    "plt.xlabel('Mean Importance')\n",
    "plt.ylabel('Features')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
